# ðŸ¤– Chat with PDF locally using Ollama + LangChain

A powerful local RAG (Retrieval Augmented Generation) application that lets you chat with your PDF documents using Ollama and LangChain. This project includes both a Jupyter notebook for experimentation and a Streamlit web interface for easy interaction.

## Project Structure
```
TalkToPDF/
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ app/                  # Streamlit application
â”‚   â”‚   â”œâ”€â”€ components/       # UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py      # Chat interface
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf.py       # PDF display
â”‚   â”‚   â”‚   â””â”€â”€ sidebar.py   # Sidebar controls
â”‚   â”‚   â””â”€â”€ main.py          # Main app
â”‚   â””â”€â”€ core/                 # Core functionality
â”‚       â”œâ”€â”€ document.py       # Document processing
â”‚       â”œâ”€â”€ embeddings.py     # Vector embeddings
â”‚       â”œâ”€â”€ llm.py           # LLM setup
â”‚       â””â”€â”€ rag.py           # RAG pipeline
â”œâ”€â”€ data/                     # Data storage
â”‚   â”œâ”€â”€ pdf/                 # sample PDFs
â”‚   â””â”€â”€ vectors/             # Vector DB storage
â”œâ”€â”€ notebooks/               # Jupyter notebooks
â”‚   â””â”€â”€ test/                # Experimental notebooks
â””â”€â”€ run.py                   # Application runner
```

## Features

- Fully local processing - no data leaves your machine
- PDF processing with intelligent chunking
- Multi-query retrieval for better context understanding
- Advanced RAG implementation using LangChain
- Clean Streamlit interface
- Jupyter notebook for experimentation

## Setup

### Prerequisites

1. **Install Ollama**
   - Visit [Ollama's website](https://ollama.ai) to download and install
   - Pull required models:
     ```bash
     ollama run gemma2:2b  # or your preferred model
     ollama pull nomic-embed-text
     ```

2. **Clone Repository**
   ```bash
   git clone https://github.com/YRKaflay/TalkToPDF.git
   cd TalkToPDF
   ```

3. **Set Up Environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: .\venv\Scripts\activate
   pip install -r requirements.txt
   ```

   Key dependencies and their versions:
   ```txt
   ollama==0.4.4
   streamlit==1.40.0
   pdfplumber==0.11.4
   langchain==0.1.20
   langchain-core==0.1.53
   langchain-ollama==0.0.2
   chromadb==0.4.22
   ```

### Running App

#### Option 1: Streamlit Interface
```bash
python run.py
```
Then open your browser to `http://localhost:8501`


#### Option 2: Jupyter Notebook
```bash
jupyter notebook
```
Open `test.ipynb` to experiment with the code
